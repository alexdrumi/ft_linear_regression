# create a version with gradient descent 
# calculate p values to make sure that this result isnt due to random chance
# create prorgam1 and program2
# compare it with the analytical solution


Prediction Program:
Initialize Parameters: Before running the program, set the initial values of the parameters 
�
0
θ 
0
​
  and 
�
1
θ 
1
​
  to 0.
User Input for Mileage: Prompt the user to input the mileage of the car for which they want to predict the price.
Calculate Estimated Price: Use the formula 
estimatePrice
(
�
�
�
�
�
�
�
)
=
�
0
+
(
�
1
×
�
�
�
�
�
�
�
)
estimatePrice(mileage)=θ 
0
​
 +(θ 
1
​
 ×mileage) to calculate the estimated price.
Display the Result: Output the estimated price based on the provided mileage.
Training Program (Gradient Descent Implementation):
Load Data: Read the dataset which contains the mileage and price of cars.
Initialize Parameters: Start with 
�
0
θ 
0
​
  and 
�
1
θ 
1
​
  set to 0 (or other values based on previous runs if you implement iterative training with updated values).
Set the Learning Rate: Choose a suitable learning rate (
�
α) for the gradient descent algorithm.
Perform Gradient Descent:
Compute Predicted Prices: For each data point in the dataset, calculate the predicted price using the current values of 
�
0
θ 
0
​
  and 
�
1
θ 
1
​
 .
Calculate Gradient: Compute the gradient of the loss function (Mean Squared Error, MSE) with respect to 
�
0
θ 
0
​
  and 
�
1
θ 
1
​
 . Use the provided formulas:
tmp
�
0
=
�
�
∑
�
=
0
�
−
1
(
estimatePrice
(
�
�
�
�
�
�
�
[
�
]
)
−
�
�
�
�
�
[
�
]
)
tmpθ 
0
​
 = 
m
α
​
 ∑ 
i=0
m−1
​
 (estimatePrice(mileage[i])−price[i])
tmp
�
1
=
�
�
∑
�
=
0
�
−
1
(
estimatePrice
(
�
�
�
�
�
�
�
[
�
]
)
−
�
�
�
�
�
[
�
]
)
×
�
�
�
�
�
�
�
[
�
]
tmpθ 
1
​
 = 
m
α
​
 ∑ 
i=0
m−1
​
 (estimatePrice(mileage[i])−price[i])×mileage[i]
Simultaneous Update: Update 
�
0
θ 
0
​
  and 
�
1
θ 
1
​
  simultaneously using the computed temporary values:
�
0
=
�
0
−
tmp
�
0
θ 
0
​
 =θ 
0
​
 −tmpθ 
0
​
 
�
1
=
�
1
−
tmp
�
1
θ 
1
​
 =θ 
1
​
 −tmpθ 
1
​
 
Iteration: Repeat the gradient descent steps for a specified number of iterations or until the changes in 
�
0
θ 
0
​
  and 
�
1
θ 
1
​
  are below a certain threshold, indicating convergence.
Save Model Parameters: Once training is complete and the model has converged, save the values of 
�
0
θ 
0
​
  and 
�
1
θ 
1
​
  for use in the prediction program.
Additional Tips:
Data Visualization: Before starting the gradient descent, it might be helpful to visualize the data (mileage vs. price) to understand the relationship and check if a linear model is appropriate.
Learning Rate Adjustment: Be mindful of the learning rate; too high a rate can cause divergence, while too low a rate can slow down the convergence.
Convergence Criteria: Define clear criteria for convergence, such as a minimal change in cost between iterations or a maximum number of iterations.
By following these steps, you should be able to effectively implement the required programs for predicting car prices using simple linear regression and training the model with gradient descent.